{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "setup-title",
   "metadata": {},
   "source": [
    "# Colab Setup for Korean Character Recognition\n",
    "\n",
    "Run this notebook ONCE before running main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataloader-funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "def get_class_names(feature_dir: str) -> List[str]:\n",
    "    return sorted([f[:-4] for f in os.listdir(feature_dir) if f.endswith(\".npy\")])\n",
    "\n",
    "def load_hog_features(feature_dir: str, selected_classes: Optional[List[str]] = None, max_samples_per_class: Optional[int] = None, shuffle: bool = True, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    class_names = get_class_names(feature_dir)\n",
    "    if selected_classes is not None:\n",
    "        class_names = [c for c in class_names if c in selected_classes]\n",
    "    X_list, y_list = [], []\n",
    "    for label_idx, cls in enumerate(class_names):\n",
    "        path = os.path.join(feature_dir, f\"{cls}.npy\")\n",
    "        if not os.path.exists(path): continue\n",
    "        feats = np.load(path)\n",
    "        if max_samples_per_class and len(feats) > max_samples_per_class:\n",
    "            feats = feats[np.random.default_rng(random_state).choice(len(feats), max_samples_per_class, replace=False)]\n",
    "        X_list.append(feats)\n",
    "        y_list.append(np.full(len(feats), label_idx, dtype=np.int64))\n",
    "    X, y = np.vstack(X_list), np.concatenate(y_list)\n",
    "    if shuffle:\n",
    "        indices = np.random.default_rng(random_state).permutation(len(X))\n",
    "        X, y = X[indices], y[indices]\n",
    "    return X, y, class_names\n",
    "\n",
    "def _train_test_split(X, y, train_ratio=0.8, test_ratio=0.2, random_state=42, stratify=True):\n",
    "    strat = y if stratify else None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1.0 - train_ratio), random_state=random_state, stratify=strat)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"[OK] Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"Upload features.zip (create with: zip -r features.zip features/hog-extended/)\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if 'features.zip' in uploaded:\n",
    "    with zipfile.ZipFile('features.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    if os.path.exists('features/hog-extended'):\n",
    "        npy_count = len([f for f in os.listdir('features/hog-extended') if f.endswith('.npy')])\n",
    "        print(f\"[OK] Extracted {npy_count} files\")\n",
    "    else:\n",
    "        print(\"[ERROR] Extraction failed\")\n",
    "else:\n",
    "    print(\"[ERROR] No file uploaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dirs",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "print(\"[OK] Directories created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, classes = load_hog_features('features/hog-extended', max_samples_per_class=10)\n",
    "print(f\"[OK] Test: {len(classes)} classes, {len(X)} samples, {X.shape[1]} dims\")\n",
    "print(\"Setup complete! Run main.ipynb now\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
